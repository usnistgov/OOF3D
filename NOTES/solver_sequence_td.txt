tatic*- text -*-
# $RCSfile: solver_sequence_td.txt,v $
# $Revision: 1.1.2.1 $
# $Author: langer $
# $Date: 2014/07/03 15:15:28 $


  The sequence of operations that happens when you press the 
"Solve" button, on the time-dependent branch, which is now
the main branch.

  Starting State:
  ---------------

  There is a mesh, on which one or more subproblems have been
defined.  Mesh elements have materials, and the subproblems have
defined and active fields, and defined equations.

  The fields have been initialized, and the user has selected
a solver for each subproblem, as well as specified the order
in which the subproblems are to be solved.  This all happens
on the solver page.

  The user may also have specified entries in the output
schedule.  There is a known, specified end time, and optionally
an initial step size, which might be the default or might have
been provided by the user.

  The solver objects have also been filled in via the "Set Solver"
button (menu item in subproblemmenu.py), which are a Linearity 
object and a StepDriver object.  The object which is called a 
"solver" in the UI is the second of these, the StepDriver object.
This menu item sets the ".linearity" and ".solver" attributes
of the subproblem context.

  Broad categories of StepDrivers are Static, Uniform, and Adaptive,
as explained in timestepper.py.  Static steppers just equilibrate,
Uniform steppers don't modify their time-step sizes, and 
Adaptive steppers can modify their time-step size to control
accuracy.

  StepDriver objects contain TimeStepper objects within them,
except the AdaptiveStepper, which contains a "QCTimeStepper"
object.  The QC stands for "Quality Controlled".  This is a distinct 
class hierarchy (currently with only one level) from the TimeStepper 
class tree.  The TimeStepper objects take individual steps, and the 
StepDriver coordinates multiple steps.


  What Actually Happens:
  ----------------------

  The solver button is on the Solver page, which is defined in
SRC/engine/IO/GUI/timePage.py.  Clicking it runs the Solve menu
item from the Mesh menu, OOF.Mesh.Solve, whose arguments are just
the mesh, the start-time, and the end-time. 

  This menu item is defined in SRC/engine/IO/meshmenu.py, the 
callback is _solve, towards the end of the file.

  This function calls solver_precompute on the mesh context,
then calls evolve.evolve with the context, start-time, and
end-time.

  The evolve function is in SRC/engine/evolve.py.
At this point, a lot of the data stored in the mesh context is read
to figure out what to do.  In particular, the order that drivers
are applied to subproblems is now determined.  The evolve function
makes an ordered list of subproblems, and first solves the static
ones at the initial time, to ensure that they form a reasonable 
basis for boundary-conditions for other problems and as the 
starting-points for interpolation, if required.

  Then, for each target time in the outputSchedule, it tries to
evolve all the subproblems to a consistent state at that target
time.  Inside this loop, there's a call to "evolve_to", which 
evolves the set of subproblems as far as it can, and returns
how far it got, as well as the suggested time-step to use
next time.
  Evolve iterates over evolve_to calls until it reaches the 
target time specified by the output schedule.


  Evolve_to builds the linear system for all the subproblems.
The DOF and equation mapping is done, along with BC applications,
in each subproblem's make_linear_system routine.
  Evolve_to initializes subproblems, and caches various useful values.
It then enters the consistency loop, in which the problem is solved
(by running linearity.step), the end values recorded, bcs expanded,
and inequality constraints converted to equality constraints where
violations have occurred.

  After all the subproblems have been run, a consistency check
is done to see if everybody made it to the target time, and if
so, if everybody got the same set of values as last time. 
When this is true, evolve_to exits.  As long as this is not
true, evolve_to keeps iterating, possibly reducing the time-step
size.



Linear System Construction:
---------------------------

  The subproblem's make_linear_system routine is called with a
time argument.  It's in csubproblem.C.

  CSubProblem::make_linear_system:

  It constructs a LinearizedSystem object of the appropriate
size, and iterates over the elements in the subproblem, calling
each element's make_linear_system routine with itself and
a pointer to the linear system object.

  The linear system is consolidated (duplicate indices are merged),
and the pointer is returned.



  Element::make_linear_system:

  Calls mat->begin_element, then iterates over gauss points and,
at each gauss point, calls material->make_linear_system.  By this
time, we have the local DOF map, which is a std::vector<int>.

  It then calls mat->end_element.



  Material::make_linear_system:

  Iterates over active fluxes.  For each flux, it builds a 
SmallSystem object, which consists of three SmallMatrix objects, 
one for each degree of time-dependence (0, 1, and 2).  

  Then, for all the properties which contribute to the active flux,
calls property->flux_matrix, and then calls property->flux_offset.
The SmallSystem object is then put in the fluxdata map, indexed by the
flux iterator which is looping over active fluxes.

  Then it iterates over equations to make the direct contributions.
For each equation, build another SmallSystem object, find all
the properties from the eqnpropmap, and for each property,
call force_matrix and force_offset to populate the equation 
data object.

  Then, within the equation loop, calls the equation's make_linear_system
routine with the equation matrix (a SmallSystem object) and the
fluxdata object.  The equation is responsible for filling in the
master stiffness/damping/inertia matrices in the linear system.



  Equation::make_linear_system

  This routine is different for different equation classes.
  The general task is to take the fluxdata and eqndata values
in the passed-in SmallSystem objects, and map them into the master
stiffness matrix.  For direct equation contributions, this is 
straightforward.  For flux contributions to divergence equations,
you have to multiply by the shape function dervative, include the 
minus sign for the by-parts integration, and contract over the 
spatial degrees of freedom.

  The guass-point weight multiplication happens in here.

  Pointwise constraint equations will just fill in the appropriate
rows and columns, and not do the gauss-point weight multiplication,
since they are not doing an integral.


  ------------------------

  Object descriptions:

  The linearized system is populated as described above.

  The object itself is in the linearizedsystem files, which
have h, C, spy, and swg extensions.

  The linearized system is mostly a data container, but it has some
special accessor methods customized for various problem types.

  The comments at the start of linearizedsystem.h are a good start.

  Matrices are M, C, K, and J, from the basic equation scheme:

  M x'' + C x' + K x + f = 0, where primes are time derivatives.

  J is the Jacobian, it's the derivative of the static equilibrium
equation with respect to the field DOFs.  For some classes of problems
(linear static, at least), J and K are numerically identical.

  There are also vectors, body_rhs, force_bndy_rhs, and fix_bndy_rhs,
which contain contributions to the rhs from non-property entities.
For instance, I think body_rhs is contributed to by the thermal
expansion? 

  Matrices and vectors are stored in index order -- I think this means
mesh index, which is the same order as subproblem index, but the 
subproblem index set is a subset of the mesh index set.

  Accessor functions:

  There are three schemes, "plain" (no suffix), augmented (suffix a),
and time-derivative (suffix d).  "Augmennted" routines assume (and operate
on) DOF vectors that are the regular DOFs followed by their time 
derivatives.  "Plain" routines just do the ordinary thing, and 
"derivative" routines return (or set) the time derivatives of the DOFs.

  The DOF accessor functions respect these suffixes, so that e.g. C_MCKa 
gets the augmented matrix  [[ K 0 ] [ 0 C]] (or whatever) that is the
effective-K matrix for the augmented DOF vector. 

  When you build up the matrix during the build_linear_system 
call chain, you call the various insertion routines, which populate
the corresponding data objects.

  At solution time, you can retreive various things.

  For the plasticity problem in particular, we care about:

 - The sub-part of the J matrix corresponding to independent eqns and
      free DOFs.
 - The RHS part that includes the contributions of the fixed BCs.

  The first one comes from J_MCK, although I think K_MCK is numerically 
the same.

  The second one comes from rhs_MCK().

  There is a routine, find_fixed_bndy_rhs, which takes a list of DOFs
and builds the linearizedsystem's internal data object -- we need this
to be up to date for our "mixed-time" K-solving trick.

  In our stepper, we call femesh.invoke_fixed_bcs with a new time.
Does this set up the linearized system correctly?
  
  Call chain:

  Stepper (engine/incremental.py):  femesh.invoke_fixed_bcs.
  FEMesh (engine/femesh.spy):  _invoke_fixed_bcs loops over boundaries,
                              calls their invokeFixed() routine.
  Boundary: (engine/boundary.py): invokeFixed loops over bc's, and 
                              calls "applyBC" on the bc.
  B Condition: (bdycondition.py): Calls linsys routines which manipulate 
                                   the indices, setting the value in
                                   the field.

  Actual answer:  We need to run the subproblemcontext's BC
machinery to get all of this right.

